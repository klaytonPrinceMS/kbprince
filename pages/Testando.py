import streamlit as st
import pandas as pd
import numpy as np
import requests
import os
import plotly.express as px
import plotly.graph_objects as go
from mlxtend.frequent_patterns import apriori, fpgrowth, association_rules
from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN, BisectingKMeans
import scipy.cluster.hierarchy as sch
import matplotlib.pyplot as plt
from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.multioutput import MultiOutputClassifier
from sklearn.neural_network import MLPRegressor
import streamlit_authenticator as stauth
import yaml
from yaml.loader import SafeLoader
import bcrypt


# --- 1. CONFIGURA√á√ïES T√âCNICAS E EST√âTICAS ---
ARQUIVO_CAIXA = "resultadoJogoMegaSena.xlsx"
CAIXA_URL = "https://servicebus2.caixa.gov.br/portaldeloterias/api/resultados/download?modalidade=Mega-Sena"
COR_QUENTE = "#FF4B4B"
COR_FRIO = "#007BFF"
NOME_SISTEMA = "Mega Sena"
VERSAO = "SIPP v2.0.20260105"
PROGRAMADOR = "PRINCE, K.B"
LINK_PESSOAL = "https://klaytonprincems.github.io/site/"
cols_b = ['Bola1', 'Bola2', 'Bola3', 'Bola4', 'Bola5', 'Bola6']
st.set_page_config(    page_title=NOME_SISTEMA,    page_icon="üçÄ",    layout="wide",    initial_sidebar_state='expanded',    menu_items={"About": LINK_PESSOAL} )
st.markdown(f"""    <style>    .main-title {{text-align: center; color: {COR_QUENTE}; font-weight: bold; margin-bottom: 20px;}}    .stButton>button {{width: 100%; font-weight: bold; border-radius: 10px; height: 45px;}}    .footer-text {{text-align: center; padding: 20px; color: #888; font-size: 14px;}}    .crisp-box {{background-color: #f0f2f6; padding: 20px; border-radius: 10px; border-left: 5px solid {COR_FRIO}; margin-bottom: 10px;}}    </style>    """, unsafe_allow_html=True)





# --- 2. MOTOR DE DADOS ---

def baixar_dados():
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        res = requests.get(CAIXA_URL, headers=headers, timeout=30)
        if res.status_code == 200:
            with open(ARQUIVO_CAIXA, "wb") as f: f.write(res.content)
            return True
        return False
    except Exception as e:
        st.error(f"Falha no download dos dados: {e}")
        return False
@st.cache_data
def processar_base_completa():
    if not os.path.exists(ARQUIVO_CAIXA):
        if not baixar_dados():
            return None, None
    try:
        df = pd.read_excel(ARQUIVO_CAIXA, engine='openpyxl')
        df.columns = [str(c).strip() for c in df.columns]
        df = df.dropna(subset=["Concurso"])
        df["Concurso"] = df["Concurso"].astype(int)

        cols_bolas = ['Bola1', 'Bola2', 'Bola3', 'Bola4', 'Bola5', 'Bola6']
        df_melt = df.melt(id_vars=["Concurso"], value_vars=cols_bolas, value_name='N').dropna()
        df_bin = pd.crosstab(df_melt["Concurso"], df_melt['N'])
        for i in range(1, 61):
            if i not in df_bin.columns: df_bin[i] = 0
        df_bin = df_bin.reindex(columns=sorted(df_bin.columns)).reset_index()
        return df, df_bin
    except Exception as e:
        st.error(f"Erro ao processar o arquivo Excel: {e}")
        return None, None
@st.cache_data
def processar_base_par_soma(df_bruto_f):
    paridade = df_bruto_f[cols_b].apply(lambda x: sum(1 for n in x if n % 2 == 0), axis=1)
    df_par = pd.DataFrame({
        'Concurso': df_bruto_f["Concurso"],
        'Pares': paridade,
        '√çmpares': 6 - paridade,
        'Soma': df_bruto_f[cols_b].sum(axis=1)
    })
    return df_par
@st.cache_data
def processar_quadrantes(df_f):
    def identificar_quadrante(n):
        row = (n - 1) // 10
        col = (n - 1) % 10
        if row < 3:
            return "Q1" if col < 5 else "Q2"
        else:
            return "Q3" if col < 5 else "Q4"
    quadrantes_contagem = []
    for _, row in df_f[cols_b].iterrows():
        qs = [identificar_quadrante(n) for n in row]
        quadrantes_contagem.append({
            "Q1": qs.count("Q1"), "Q2": qs.count("Q2"),
            "Q3": qs.count("Q3"), "Q4": qs.count("Q4")
        })
    return pd.DataFrame(quadrantes_contagem, index=df_f["Concurso"])
@st.cache_data
def executar_agnes(df_bin_f, n_clusters=4, metric='euclidean', linkage='ward'):
    data = df_bin_f.drop(columns=["Concurso"], errors='ignore').copy()
    data.columns = data.columns.astype(str)
    model = AgglomerativeClustering(        n_clusters=n_clusters,        metric=metric,        linkage=linkage) # Agora o linkage √© um par√¢metro
    labels = model.fit_predict(data)
    return labels
@st.cache_data
def plotar_dendrograma_range(df_bin_f, c_ini, c_fim):
    df_range = df_bin_f[(df_bin_f["Concurso"] >= c_ini) & (df_bin_f["Concurso"] <= c_fim)].copy()
    if df_range.empty:
        return None
    concursos = df_range['Concurso'].astype(str).values
    data = df_range.drop(columns=["Concurso"], errors='ignore')
    data.columns = data.columns.astype(str)
    linkage_matrix = sch.linkage(data, method='ward')
    fig, ax = plt.subplots(figsize=(12, 6))
    sch.dendrogram(linkage_matrix, labels=concursos, leaf_rotation=90, leaf_font_size=9, ax=ax)
    ax.set_title(f"Dendrograma: De {c_ini} at√© {c_fim}")
    ax.set_ylabel("Dist√¢ncia (Dissimilaridade)")
    plt.tight_layout()
    return fig
@st.cache_data
def executar_diana(df_bin_f, n_clusters=4):
    data = df_bin_f.drop(columns=["Concurso"], errors='ignore').copy()
    data.columns = data.columns.astype(str)
    model = BisectingKMeans(n_clusters=n_clusters, random_state=42, bisecting_strategy='biggest_inertia')
    labels = model.fit_predict(data)
    return labels
@st.cache_data
def executar_dbscan(df_bin_f, eps=0.5, min_samples=3):
    data = df_bin_f.drop(columns=["Concurso"], errors='ignore').copy()
    data.columns = data.columns.astype(str)
    model = DBSCAN(eps=eps, min_samples=min_samples, metric='euclidean')
    labels = model.fit_predict(data)
    return labels
@st.cache_data
def realizar_predicao_mlp_custom(df_bin_f, c_ini, c_fim):
    """
    Realiza uma predi√ß√£o multi-label usando MLPRegressor, a abordagem correta
    para prever m√∫ltiplas probabilidades cont√≠nuas.
    """
    df_modelo = df_bin_f[(df_bin_f["Concurso"] >= c_ini) & (df_bin_f["Concurso"] <= c_fim)].copy()
    if len(df_modelo) < 20:
        return None
    # Garante que estamos usando apenas as 60 dezenas
    dezenas_cols = list(range(1, 61))
    data = df_modelo[dezenas_cols].values
    X = data[:-1]
    y = data[1:]
    # SOLU√á√ÉO: Usar MLPRegressor em vez de MLPClassifier
    model = MLPRegressor(        hidden_layer_sizes=(120, 80, 40),        activation='relu',        solver='adam',        alpha=0.001,        learning_rate='adaptive',        max_iter=1000,        early_stopping=True,        validation_fraction=0.1,        random_state=42    )
    # O fit agora funciona, pois MLPRegressor suporta multi-output nativamente
    model.fit(X, y)
    # A predi√ß√£o agora retorna diretamente os valores previstos (nossas probabilidades)
    ultimo_concurso_conhecido = data[-1].reshape(1, -1)
    probabilidades = model.predict(ultimo_concurso_conhecido)[0]
    # Garante que as probabilidades fiquem no intervalo [0, 1]
    probabilidades = np.clip(probabilidades, 0, 1)
    return probabilidades
@st.cache_data
def realizar_predicao_rf_custom(df_bin_f, c_ini, c_fim, n_estimators=100, max_depth=10):
    """
    Realiza uma predi√ß√£o multi-label usando RandomForestClassifier de forma
    otimizada e robusta, garantindo a estrutura correta dos dados.
    """
    df_modelo = df_bin_f[(df_bin_f["Concurso"] >= c_ini) & (df_bin_f["Concurso"] <= c_fim)].copy()
    if len(df_modelo) < 30:
        return None

    # --- IN√çCIO DA CORRE√á√ÉO ---
    # 1. Garante que estamos usando apenas as 60 dezenas como colunas.
    #    As colunas no df_bin_f s√£o n√∫meros (1, 2, ..., 60).
    dezenas_cols = list(range(1, 61))
    data = df_modelo[dezenas_cols].values
    # Agora 'data' tem GARANTIDAMENTE 60 colunas (√≠ndices 0-59).
    # --- FIM DA CORRE√á√ÉO ---
    X = data[:-1]
    y = data[1:]
    cols_com_variacao = [i for i in range(y.shape[1]) if len(np.unique(y[:, i])) > 1]
    if not cols_com_variacao:
        return np.zeros(60)
    y_filtrado = y[:, cols_com_variacao]
    base_classifier = RandomForestClassifier(        n_estimators=n_estimators,        max_depth=max_depth,        random_state=42,        n_jobs=None    )
    multi_target_forest = MultiOutputClassifier(base_classifier, n_jobs=-1)
    multi_target_forest.fit(X, y_filtrado)
    ultimo_concurso_conhecido = data[-1].reshape(1, -1)
    probabilidades_parciais = multi_target_forest.predict_proba(ultimo_concurso_conhecido)
    probs_agregadas = np.zeros(60)
    for i, prob in enumerate(probabilidades_parciais):
        indice_dezena_original = cols_com_variacao[i]
        classes_aprendidas = multi_target_forest.estimators_[i].classes_
        if 1 in classes_aprendidas:
            idx_classe_1 = np.where(classes_aprendidas == 1)[0][0]
            prob_classe_1 = prob[0][idx_classe_1]
            probs_agregadas[indice_dezena_original] = prob_classe_1
    return probs_agregadas


def gerar_hash(senha_plana):
    # Transforma a senha em bytes e gera o salt
    senha_bytes = senha_plana.encode('utf-8')
    salt = bcrypt.gensalt()
    # Gera o hash
    hash_resultado = bcrypt.hashpw(senha_bytes, salt)
    return hash_resultado.decode('utf-8')
print(f'Gerando senha {gerar_hash("jose")}')


# 1. Carregar arquivo YAML
caminho_base = r"F:\Documents\klayton\Git_hub2026\kbprince"
caminho_yaml = os.path.join(caminho_base, "usuarios.yaml")

with open(caminho_yaml) as file:
    config = yaml.load(file, Loader=SafeLoader)

# 2. Criar o objeto de autentica√ß√£o (SEM o pre-authorized)
authenticator = stauth.Authenticate(
    config['credentials'],
    config['cookie']['name'],
    config['cookie']['key'],
    config['cookie']['expiry_days']
)

# 3. Renderizar formul√°rio de login
# Nas vers√µes novas, usamos o m√©todo login sem passar 'main' se quiser o padr√£o
# login retorna apenas o status de autentica√ß√£o diretamente
authenticator.login()

# 4. L√≥gica de Verifica√ß√£o
if st.session_state["authentication_status"]:
    # BOT√ÉO DE SAIR
    authenticator.logout('Sair')

    st.info(f'Bem-vindo, {st.session_state["name"]}')


    # --- 3. INTERFACE E L√ìGICA ---
    st.markdown(f"<h1 class='main-title'>üçÄ {NOME_SISTEMA}</h1>", unsafe_allow_html=True)
    df_bruto, df_binario = processar_base_completa()

    # Inicio do sidebar, menu lateral
    if df_bruto is not None and df_binario is not None:
        # --- SIDEBAR: CONFIGURA√á√ÉO COMPLETA ---
        st.sidebar.header("‚öôÔ∏è Minera√ß√£o")
        min_c, max_c = int(df_bruto["Concurso"].min()), int(df_bruto["Concurso"].max())

        # Atalhos r√°pidos
        st.sidebar.write("**Intervalo de jogos**")
        c1, c2 = st.sidebar.columns(2)
        if c1.button("100"): st.session_state.ini, st.session_state.fim = max_c - 100, max_c
        if c2.button("Total"): st.session_state.ini, st.session_state.fim = min_c, max_c

        # Slider e Input para Precis√£o 100%
        val_ini = st.session_state.get('ini', max_c - 500)
        val_fim = st.session_state.get('fim', max_c)
        range_c = st.sidebar.slider("Janela Temporal:", min_c, max_c, (val_ini, val_fim))

        col_i, col_f = st.sidebar.columns(2)
        c_ini = col_i.number_input("Primeiro:", min_c, max_c, range_c[0])
        c_fim = col_f.number_input("Ultimo:", min_c, max_c, range_c[1])

        st.sidebar.write("**Def Fogo e Gelo**")
        qtd_top = st.sidebar.slider("Total:", 4, 30, 15)
        metodo = st.sidebar.selectbox("Peso de Rec√™ncia:", ["Linear", "Exponencial"])

        if st.sidebar.button("üîÑ ATUALIZAR DB"):
            if baixar_dados(): st.cache_data.clear(); st.rerun()
        # Fim do sidebar, menu lateral




        # --- O RESTANTE DO C√ìDIGO CONTINUA DAQUI ---
        # O filtro agora usar√° c_ini e c_fim que est√£o sempre sincronizados
        df_bruto_f = df_bruto[(df_bruto["Concurso"] >= c_ini) & (df_bruto["Concurso"] <= c_fim)].copy()
        df_bin_f = df_binario[(df_binario["Concurso"].astype(int) >= c_ini) & (df_binario["Concurso"].astype(int) <= c_fim)].copy()





        # ... (o resto do seu c√≥digo permanece o mesmo) ...
        df_bruto_f = df_bruto[(df_bruto["Concurso"] >= c_ini) & (df_bruto["Concurso"] <= c_fim)].copy()
        df_bin_f = df_binario[(df_binario["Concurso"].astype(int) >= c_ini) & (df_binario["Concurso"].astype(int) <= c_fim)].copy()

        weights = np.exp(np.linspace(0, 3, len(df_bin_f))) if metodo == "Exponencial" else np.linspace(0.1, 1.0, len(df_bin_f))
        scores = df_bin_f.drop(columns=["Concurso"]).astype(float).multiply(weights, axis=0).sum()
        df_ranking = pd.DataFrame({'N√∫mero': scores.index.astype(int), 'Score': scores.values}).sort_values('Score', ascending=False)

        df_par_soma = processar_base_par_soma(df_bruto_f)
        # Paridade, Soma, Fogo e Gelo, Quadrantes
        try:
            tabs1 = st.tabs(["", "üìàü™ô Paridade", "üìà‚ûï Soma", "üöÄ Fogo e Gelo", "üü¶ Quadrantes"])
            with tabs1[0]:
                st.info("Navegue pelas abas para explorar as an√°lises de tend√™ncias b√°sicas.")
            with tabs1[1]:
                st.subheader("üìà Tend√™ncias de Paridade")
                st.bar_chart(df_par_soma.set_index('Concurso')[['Pares', '√çmpares']])
                st.dataframe(df_par_soma[['Concurso', 'Pares', '√çmpares']].iloc[::-1], width="stretch", hide_index=True)
            with tabs1[2]:
                st.subheader("üìà Tend√™ncias de Soma com An√°lise Estat√≠stica")

                # 1. Calcular as m√©tricas estat√≠sticas necess√°rias
                soma_media = df_par_soma['Soma'].mean()
                soma_std = df_par_soma['Soma'].std()
                limite_superior = soma_media + soma_std
                limite_inferior = soma_media - soma_std

                # Exibir as m√©tricas em colunas para uma visualiza√ß√£o limpa
                c1, c2, c3 = st.columns(3)
                c1.metric("M√©dia da Soma", f"{soma_media:.2f}")
                c2.metric("Limite Superior (M√©dia + 1œÉ)", f"{limite_superior:.2f}")
                c3.metric("Limite Inferior (M√©dia - 1œÉ)", f"{limite_inferior:.2f}")

                # 2. Usar Plotly para criar um gr√°fico com m√∫ltiplas camadas
                fig = go.Figure()
                # Adiciona a linha principal da Soma
                fig.add_trace(go.Scatter(                x=df_par_soma['Concurso'],                y=df_par_soma['Soma'],                mode='lines',                name='Soma das Dezenas',                line=dict(color='#1f77b4') )) # Cor azul padr√£o
                # Adiciona a linha da M√©dia
                fig.add_hline(                y=soma_media,                line_dash="dash",                line_color="#ff7f0e",                  annotation_text="M√©dia",                annotation_position="bottom right"            ) # Laranja #ff7f0e
                # Adiciona a linha do Limite Superior
                fig.add_hline(                y=limite_superior,                line_dash="dot",                line_color="#d62728",                  annotation_text="M√©dia +1œÉ",                annotation_position="bottom right"            ) # Vermelho #d62728
                # Adiciona a linha do Limite Inferior
                fig.add_hline(                y=limite_inferior,                line_dash="dot",                line_color="#2ca02c",                  annotation_text="M√©dia -1œÉ",                annotation_position="bottom right"            ) # Verde #2ca02c
                # Ajustes finais de layout do gr√°fico
                fig.update_layout(                title="Evolu√ß√£o da Soma das Dezenas com Bandas de M√©dia",                xaxis_title="Concurso",                yaxis_title="Soma",                showlegend=True            )
                st.plotly_chart(fig, width="stretch")
                # A tabela de dados continua a mesma
                st.dataframe(df_par_soma[['Concurso', 'Soma']].iloc[::-1], width="stretch", hide_index=True)
            with tabs1[3]:
                st.subheader("üöÄ Fogo e Gelo")
                # 1. Seleciona os dados (como antes)
                top = df_ranking.head(qtd_top)
                bottom = df_ranking.tail(qtd_top)
                # 2. Adiciona uma coluna de categoria para diferenciar os grupos
                top['Categoria'] = 'Quente'
                bottom['Categoria'] = 'Frio'
                # 3. Concatena os dois DataFrames em um s√≥
                df_plot = pd.concat([top, bottom])
                # 4. SOLU√á√ÉO: Ordena o DataFrame pelo n√∫mero da dezena
                df_plot = df_plot.sort_values('N√∫mero')
                # 5. Cria o gr√°fico de barras
                fig = px.bar(                df_plot,                x='N√∫mero',                y='Score',                color='Categoria',                title="Extremos de Tend√™ncia: Dezenas Quentes vs. Frias",                labels={'N√∫mero': 'Dezena', 'Score': 'Pontua√ß√£o de Tend√™ncia'},                color_discrete_map={
                        'Quente': COR_QUENTE,
                        'Frio': COR_FRIO
                    }            )

                # 6. SOLU√á√ÉO: For√ßa o eixo X a ter a categoria completa de 1 a 60
                # Isso garante que as barras apare√ßam em suas posi√ß√µes corretas no volante.
                fig.update_xaxes(
                    type='category',
                    categoryorder='array',  # Garante a ordem que definimos
                    categoryarray=list(range(1, 61))  # Define a ordem e o range completo
                )

                st.plotly_chart(fig, width="stretch")

                # A exibi√ß√£o da tabela de ranking completa continua a mesma
                st.write("**Classifica√ß√£o Completa por Pontua√ß√£o (Ranking SIPP)**")
                st.dataframe(df_ranking, width="stretch", hide_index=True)
            with tabs1[4]:
                st.subheader("üü¶ Distribui√ß√£o por Quadrantes")
                df_q = processar_quadrantes(df_bruto_f)
                fig_q = px.bar(df_q.reset_index(), x="Concurso", y=["Q1", "Q2", "Q3", "Q4"], title="Equil√≠brio de Quadrantes por Concurso")
                st.plotly_chart(fig_q, width="stretch")
                c1, c2, c3, c4 = st.columns(4)
                c1.metric("M√©dia Q1", f"{df_q['Q1'].mean():.2f}")
                c2.metric("M√©dia Q2", f"{df_q['Q2'].mean():.2f}")
                c3.metric("M√©dia Q3", f"{df_q['Q3'].mean():.2f}")
                c4.metric("M√©dia Q4", f"{df_q['Q4'].mean():.2f}")
                st.dataframe(df_q.iloc[::-1], width="stretch")
        except Exception as e:
            st.error(f"Erro em Dados brutos, Binarios, Governan√ßa e Metodologia.  \n{e}")

        # Percentis, Associa√ß√£o, Analise
        try:
            st.divider()
            tabs2 = st.tabs(["", "üéØ Percentis", "üîó Associa√ß√£o", "üîç Analisador"])
            with tabs2[0]:
                st.info("Explore as abas para an√°lises estat√≠sticas e de associa√ß√£o.")
            with tabs2[1]:
                st.subheader("üéØ An√°lise de Percentis")
                p_alta = df_ranking['Score'].quantile(0.80)
                p_baixa = df_ranking['Score'].quantile(0.20)
                c1, c2 = st.columns(2)
                c1.metric("Corte Percentil 80 (Quentes)", f"{p_alta:.2f}")
                c2.metric("Corte Percentil 20 (Frios)", f"{p_baixa:.2f}")
                fig_p = px.ecdf(df_ranking, x="Score", title="Curva de Probabilidade Acumulada")
                st.plotly_chart(fig_p, width="stretch")
            with tabs2[2]:
                st.subheader("üîó Minera√ß√£o de Regras de Associa√ß√£o")
                col_alg, col_sup, col_conf = st.columns(3)
                alg_assoc = col_alg.selectbox("Algoritmo:", ["FP-Growth", "Apriori"], key="select_assoc")
                min_sup = col_sup.slider("Suporte M√≠nimo:", 0.001, 0.05, 0.01, format="%.3f", key="slider_sup")
                min_conf = col_conf.slider("Confian√ßa M√≠nima:", 0.1, 1.0, 0.10, key="slider_conf")
                df_assoc_input = df_bin_f.drop(columns=["Concurso"]).astype(bool)
                try:
                    frequent_itemsets = fpgrowth(df_assoc_input, min_support=min_sup, use_colnames=True) if alg_assoc == "FP-Growth" else apriori(df_assoc_input, min_support=min_sup, use_colnames=True)
                    if not frequent_itemsets.empty:
                        rules = association_rules(frequent_itemsets, metric="confidence", min_threshold=min_conf)
                        if not rules.empty:
                            rules["antecedents"] = rules["antecedents"].apply(list)
                            rules["consequents"] = rules["consequents"].apply(list)
                            st.dataframe(rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']].sort_values('lift', ascending=False), width="stretch")
                        else:
                            st.warning("Nenhuma regra encontrada com a confian√ßa m√≠nima.")
                    else:
                        st.warning("Nenhum conjunto frequente encontrado com o suporte m√≠nimo.")
                except Exception as e:
                    st.error(f"Erro na associa√ß√£o: {e}")
            with tabs2[3]:
                st.subheader("üîç Analisador de Jogos Personalizados")
                dezenas_user = st.multiselect("Selecione de 4 a 15 DEZENAS:", list(range(1, 61)), key='multiselect_analisador_1')
                if 4 <= len(dezenas_user) <= 15:
                    set_user = set(dezenas_user)
                    ocorrencias = []
                    for _, row in df_bruto.iterrows():
                        sorteados = set(row[cols_b].values)
                        acertos = len(set_user.intersection(sorteados))
                        if acertos >= 4:
                            ocorrencias.append({
                                "Concurso": row["Concurso"], "Data": row.get("Data Sorteio", "N/A"),
                                "Acertos": acertos, "Ganhadores 6": row.get("Ganhadores_Sena", 0)
                            })
                    df_ocorr = pd.DataFrame(ocorrencias)
                    c1, c2, c3 = st.columns(3)
                    score_jogo = sum(df_ranking[df_ranking['N√∫mero'] == n]['Score'].values[0] for n in dezenas_user) / len(dezenas_user)
                    c1.metric("Score M√©dio SIPP", f"{score_jogo:.2f}")
                    c2.metric("Vezes Premiado (4+)", len(df_ocorr))
                    prob = (len(df_ocorr) / len(df_bruto)) * 100 if len(df_bruto) > 0 else 0
                    c3.metric("Frequ√™ncia Hist√≥rica", f"{prob:.4f}%")
                    if not df_ocorr.empty:
                        st.dataframe(df_ocorr.sort_values("Concurso", ascending=False), width="stretch")
                    else:
                        st.info("Este grupo nunca premiou com 4+ acertos.")
                else:
                    st.info("Selecione entre 4 e 15 dezenas.")
        except Exception as e:
            st.info("Erro PErcentis, Associa√ß√£o e Analisador.")

        # Clustering, Agnes, Agnes x Diana, Dendograma, DBSCAN
        try:
            st.divider()
            tabs3 = st.tabs(["", "üß© Clustering", "üß© Agnes", "üß© Agnes x Diana", "üß© Dendograma", "üß© DBSCAN"])
            with tabs3[0]:
                st.info("Explore diferentes algoritmos de clusteriza√ß√£o para encontrar padr√µes.")
            with tabs3[1]:
                st.subheader("üß© Agrupamento (Clustering) de Padr√µes")
                tipo_cluster = st.radio("Agrupar por:", ["Concursos (Padr√µes de Sorteio)", "Dezenas (Afinidade)"], key="radio_cluster")
                n_clusters = st.slider("N√∫mero de Clusters:", 2, 10, 4, key="slider_kmeans")
                data_cluster = df_bin_f.drop(columns=["Concurso"], errors='ignore').copy()
                data_cluster.columns = data_cluster.columns.astype(str)
                if tipo_cluster == "Concursos (Padr√µes de Sorteio)":
                    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10).fit(data_cluster)
                    df_bin_f['Cluster'] = kmeans.labels_
                    fig_c = px.scatter(df_bin_f, x="Concurso", y="Cluster", color=df_bin_f["Cluster"].astype(str), title="Concursos por Cluster")
                    st.plotly_chart(fig_c, width="stretch")
                else:
                    data_cluster_t = data_cluster.T
                    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10).fit(data_cluster_t)
                    df_cluster_dez = pd.DataFrame({'N√∫mero': range(1, 61), 'Cluster': kmeans.labels_})
                    for i in range(n_clusters):
                        st.write(f"**Cluster {i}:** {df_cluster_dez[df_cluster_dez['Cluster'] == i]['N√∫mero'].tolist()}")
            with tabs3[2]:
                st.subheader("üß© Agrupamento Hier√°rquico (AGNES)")

                # A interface para o usu√°rio permanece simples.
                # SOLU√á√ÉO: A chave foi renomeada para ser √∫nica e evitar conflito.
                metrica = st.selectbox(
                    "M√©trica de Dist√¢ncia:",
                    ["euclidean", "manhattan", "cosine"],
                    key="agnes_metric_selector",  # <-- CHAVE RENOMEADA E √öNICA
                    help="O m√©todo de agrupamento se ajustar√° automaticamente √† m√©trica escolhida."
                )

                # A chave do slider tamb√©m precisa ser √∫nica para esta aba.
                n_cl = st.slider("Qtd de Grupos:", 2, 8, 4, key="agnes_cluster_slider")

                if st.button("Executar AGNES", key="agnes_execute_button"):  # Adicionar key ao bot√£o tamb√©m √© uma boa pr√°tica
                    # --- L√ìGICA DE ADAPTA√á√ÉO AUTOM√ÅTICA ---
                    if metrica == 'euclidean':
                        linkage_metodo = 'ward'
                    else:
                        linkage_metodo = 'average'
                    # -----------------------------------------

                    st.info(f"Executando com a combina√ß√£o: M√©trica='{metrica}' e Linkage='{linkage_metodo}'.")

                    # Chama a fun√ß√£o com os par√¢metros corretos e seguros
                    # (Assumindo que a fun√ß√£o executar_agnes j√° foi atualizada para aceitar 'linkage')
                    labels = executar_agnes(df_bin_f, n_cl, metrica, linkage_metodo)
                    df_bin_f['Agnes_Cluster'] = labels

                    # Exibe os resultados
                    fig_agnes = px.scatter(
                        df_bin_f,
                        x="Concurso",
                        y="Agnes_Cluster",
                        color=df_bin_f["Agnes_Cluster"].astype(str),
                        title=f"Concursos por Similaridade Hier√°rquica ({metrica.capitalize()})"
                    )
                    st.plotly_chart(fig_agnes, width="stretch")
            with tabs3[3]:
                st.subheader("üß¨ AGNES vs DIANA")
                metodo_h = st.selectbox("Dire√ß√£o:", ["AGNES (Agrupar)", "DIANA (Dividir)"], key="select_h_method")
                n_h = st.slider("N√∫mero de Grupos:", 2, 10, 4, key="slider_h")
                if st.button("Executar Minera√ß√£o Hier√°rquica"):
                    labels = executar_agnes(df_bin_f, n_h) if metodo_h == "AGNES (Agrupar)" else executar_diana(df_bin_f, n_h)
                    df_bin_f['Cluster_H'] = labels
                    fig_h = px.scatter(df_bin_f, x="Concurso", y="Cluster_H", color=labels.astype(str), title=f"Resultado via {metodo_h}")
                    st.plotly_chart(fig_h, width="stretch")
            with tabs3[4]:
                st.subheader("üå≥ An√°lise Geneal√≥gica Customizada (Dendrograma)")
                min_hist, max_hist = int(df_bin_f["Concurso"].min()), int(df_bin_f["Concurso"].max())
                c_start = st.number_input("Concurso Inicial:", min_hist, max_hist, max(min_hist, max_hist - 50), key="dendro_start")
                c_end = st.number_input("Concurso Final:", min_hist, max_hist, max_hist, key="dendro_end")
                if c_start < c_end:
                    if (c_end - c_start) > 150: st.warning("Range grande pode poluir a visualiza√ß√£o.")
                    fig_d = plotar_dendrograma_range(df_bin_f, c_start, c_end)
                    if fig_d: st.pyplot(fig_d)
                else:
                    st.error("O concurso inicial deve ser menor que o final.")
            with tabs3[5]:
                st.subheader("üì° Detector de Anomalias (DBSCAN)")
                c1, c2 = st.columns(2)
                val_eps = c1.slider("Sensibilidade (Epsilon):", 0.5, 3.0, 1.2, key="slider_eps")
                val_min = c2.slider("M√≠nimo de Vizinhos:", 2, 10, 3, key="slider_min_samples")
                labels_db = executar_dbscan(df_bin_f, eps=val_eps, min_samples=val_min)
                df_bin_f['Cluster_DBSCAN'] = labels_db
                m1, m2, m3 = st.columns(3)
                total, ruidos = len(df_bin_f), list(labels_db).count(-1)
                m1.metric("Total Analisado", total)
                m2.metric("Concursos no Padr√£o", total - ruidos)
                m3.metric("Concursos no Ru√≠do", ruidos, delta=f"{(ruidos / total) * 100:.1f}%" if total > 0 else "0.0%", delta_color="inverse")
                fig_db_view = px.scatter(df_bin_f, x="Concurso", y="Cluster_DBSCAN", color=df_bin_f["Cluster_DBSCAN"].apply(lambda x: "Ru√≠do" if x == -1 else "Padr√£o"), color_discrete_map={"Ru√≠do": "red", "Padr√£o": "#00CC96"}, title="Mapa de Densidade: Padr√µes vs Anomalias")
                st.plotly_chart(fig_db_view, width="stretch")
        except Exception as e:
            st.error(f"Erro em Clustering, Agnes, Agnes x Diana, Dendograma, DBSCAN.  \n{e}")

        # Gerador, Analisador, Predi√ß√£o
        try:
            st.divider()
            tabs4 = st.tabs(["", "ü§ñ Gerador", "üîç Analisador", "ü§ñ Predi√ß√£o MLP"])
            with tabs4[0]:
                st.info("Use as ferramentas de IA para gerar jogos ou analisar probabilidades.")
            with tabs4[1]:
                st.subheader("üé≤ Gerador Inteligente de Dezenas")
                st.markdown(
                    "Use os filtros para gerar um jogo com base em restri√ß√µes estat√≠sticas. O gerador tentar√° encontrar um jogo que satisfa√ßa todas as condi√ß√µes.")

                c1, c2 = st.columns(2)

                # Widget para quantidade de n√∫meros permanece o mesmo
                qtd_gerar = c1.number_input("Quantidade de n√∫meros:", 6, 15, 6, key="gerador_qtd")

                # Widget para quantidade de pares tamb√©m permanece o mesmo
                n_pares = c2.slider("Quantidade de Pares:", 0, qtd_gerar, qtd_gerar // 2, key="gerador_pares")

                # --- IN√çCIO DA CORRE√á√ÉO DIN√ÇMICA ---

                # 1. Calcula os limites te√≥ricos da soma para a quantidade de dezenas escolhida
                soma_min_possivel = sum(range(1, qtd_gerar + 1))
                soma_max_possivel = sum(range(61 - qtd_gerar, 61))

                # 2. Define um valor padr√£o din√¢mico e razo√°vel para o slider
                #    Vamos usar uma faixa em torno do ponto m√©dio te√≥rico.
                ponto_medio = (soma_min_possivel + soma_max_possivel) / 2
                spread = (soma_max_possivel - soma_min_possivel) * 0.15  # Uma faixa de 30% em torno do meio
                default_min = max(soma_min_possivel, int(ponto_medio - spread))
                default_max = min(soma_max_possivel, int(ponto_medio + spread))

                # 3. Cria o slider de soma com os limites e valores padr√£o DIN√ÇMICOS
                st.write(
                    f"Para **{qtd_gerar} n√∫meros**, a soma pode variar de **{soma_min_possivel}** a **{soma_max_possivel}**.")
                soma_range = st.slider(
                    "Faixa de Soma:",
                    min_value=soma_min_possivel,
                    max_value=soma_max_possivel,
                    value=(default_min, default_max),  # Usa o padr√£o din√¢mico
                    key="gerador_soma_dinamico"  # Nova chave para evitar conflitos
                )
                # --- FIM DA CORRE√á√ÉO DIN√ÇMICA ---

                usar_score = st.toggle(
                    "Ponderar pela pontua√ß√£o SIPP (dezenas 'quentes')",
                    value=True,
                    help="Se ativado, o gerador dar√° prefer√™ncia √†s dezenas com maior pontua√ß√£o de tend√™ncia (quentes).",
                    key="gerador_usar_score"
                )

                if st.button("üçÄ Gerar Jogo Inteligente", key="gerador_button"):
                    # (O restante do c√≥digo para gerar e exibir o jogo permanece o mesmo)
                    with st.spinner("Procurando a combina√ß√£o perfeita..."):
                        tentativas = 0
                        jogo_encontrado = None

                        if usar_score:
                            probabilidades = df_ranking.sort_values('N√∫mero')['Score'].values
                            probabilidades /= probabilidades.sum()
                            pool_dezenas = range(1, 61)
                        else:
                            probabilidades = None
                            pool_dezenas = range(1, 61)

                        while tentativas < 5000:
                            jogo = np.random.choice(pool_dezenas, qtd_gerar, replace=False, p=probabilidades)
                            soma_jogo = sum(jogo)
                            pares_jogo = sum(1 for n in jogo if n % 2 == 0)

                            if pares_jogo == n_pares and soma_range[0] <= soma_jogo <= soma_range[1]:
                                jogo_encontrado = sorted(jogo)
                                break
                            tentativas += 1

                    if jogo_encontrado:
                        st.success("üçÄ Combina√ß√£o encontrada com sucesso!")
                        with st.container(border=True):
                            st.write("### Jogo Gerado:")
                            cols = st.columns(len(jogo_encontrado))
                            for i, num in enumerate(jogo_encontrado):
                                cols[i].markdown(
                                    f"<div style='background-color: #262730; border-radius: 50%; width: 50px; height: 50px; display: flex; justify-content: center; align-items: center; color: white; font-size: 20px; font-weight: bold;'>{num:02d}</div>",
                                    unsafe_allow_html=True
                                )
                            st.divider()
                            st.write("#### Estat√≠sticas do Jogo:")
                            soma_final = sum(jogo_encontrado)
                            pares_final = sum(1 for n in jogo_encontrado if n % 2 == 0)
                            impares_final = len(jogo_encontrado) - pares_final
                            score_jogo = df_ranking[df_ranking['N√∫mero'].isin(jogo_encontrado)]['Score'].mean()
                            m1, m2, m3, m4 = st.columns(4)
                            m1.metric("Soma Total", soma_final)
                            m2.metric("N¬∫ de Pares", pares_final)
                            m3.metric("N¬∫ de √çmpares", impares_final)
                            m4.metric("Score SIPP M√©dio", f"{score_jogo:.2f}")
                    else:
                        st.warning(
                            "N√£o foi poss√≠vel gerar um jogo com as restri√ß√µes exatas. Tente ampliar a faixa de soma ou desativar a pondera√ß√£o SIPP.")
            with tabs4[2]:
                st.subheader("üîç Analisador de Jogos Personalizados")
                dezenas_user_2 = st.multiselect("Selecione de 4 a 15 DEZENAS:", list(range(1, 61)), key='multiselect_analisador_2')
                if 4 <= len(dezenas_user_2) <= 15:
                    set_user = set(dezenas_user_2)
                    ocorrencias = []
                    for _, row in df_bruto.iterrows():
                        sorteados = set(row[cols_b].values)
                        acertos = len(set_user.intersection(sorteados))
                        if acertos >= 4:
                            ocorrencias.append({
                                "Concurso": row["Concurso"], "Data": row.get("Data Sorteio", "N/A"),
                                "Acertos": acertos, "Ganhadores 6": row.get("Ganhadores_Sena", 0)
                            })
                    df_ocorr = pd.DataFrame(ocorrencias)
                    c1, c2, c3 = st.columns(3)
                    score_jogo = sum(df_ranking[df_ranking['N√∫mero'] == n]['Score'].values[0] for n in dezenas_user_2) / len(dezenas_user_2)
                    c1.metric("Score M√©dio SIPP", f"{score_jogo:.2f}")
                    c2.metric("Vezes Premiado (4+)", len(df_ocorr))
                    prob = (len(df_ocorr) / len(df_bruto)) * 100 if len(df_bruto) > 0 else 0
                    c3.metric("Frequ√™ncia Hist√≥rica", f"{prob:.4f}%")
                    if not df_ocorr.empty:
                        st.dataframe(df_ocorr.sort_values("Concurso", ascending=False), width="stretch")
                    else:
                        st.info("Este grupo nunca premiou com 4+ acertos.")
                else:
                    st.info("Selecione entre 4 e 15 dezenas.")
            with tabs4[3]:  # Esta √© agora a sua aba unificada de "Predi√ß√£o com IA"
                st.subheader("üß† Predi√ß√£o com Intelig√™ncia Artificial")
                st.markdown("O usu√°rio escolhe qual IA usar")

                # 1. SELETOR DE MODELO: O usu√°rio escolhe qual IA usar
                modelo_escolhido = st.selectbox(
                    "Escolha o Modelo de Predi√ß√£o:",
                    ("Rede Neural (MLP)", "Floresta Aleat√≥ria (Random Forest)"),
                    key="ia_model_selector"
                )

                # Mensagem de ajuda para o usu√°rio
                if modelo_escolhido == "Rede Neural (MLP)":
                    st.markdown(
                        "O MLP √© uma rede neural profunda que busca padr√µes complexos e sequenciais nos dados. Pode ser mais lento para treinar.")
                else:
                    st.markdown(
                        "O Random Forest treina m√∫ltiplas √°rvores de decis√£o, sendo um modelo robusto, r√°pido e geralmente √≥timo para dados tabulares.")

                # 2. WIDGETS DE CONTROLE UNIFICADOS: Usam chaves √∫nicas
                c_min_ia, c_max_ia = int(df_bin_f["Concurso"].min()), int(df_bin_f["Concurso"].max())
                col_ia1, col_ia2, col_ia3 = st.columns(3)
                ini_ia = col_ia1.number_input("Treinar a partir do:", c_min_ia, c_max_ia - 1, max(c_min_ia, c_max_ia - 500),
                                              key="ia_ini_unificado")
                fim_ia = col_ia2.number_input("At√© o concurso:", ini_ia + 1, c_max_ia, c_max_ia, key="ia_fim_unificado")
                qtd_sugerida = col_ia3.slider("Qtd de DEZENAS:", 6, 30, 20, key="ia_pool_unificado")

                proximo_alvo = fim_ia + 1
                st.info(f"üéØ **Objetivo:** Prever o comportamento do concurso **{proximo_alvo}** usando **{modelo_escolhido}**.")

                # 3. BOT√ÉO E L√ìGICA CONDICIONAL
                if st.button(f"üöÄ Iniciar Treinamento com {modelo_escolhido}", key="ia_button_unificado"):

                    # Define a mensagem do spinner e a fun√ß√£o a ser chamada com base na escolha
                    if modelo_escolhido == "Rede Neural (MLP)":
                        spinner_message = "A rede neural est√° processando..."
                        funcao_predicao = realizar_predicao_mlp_custom
                    else:
                        spinner_message = "A floresta aleat√≥ria est√° crescendo e analisando os dados..."
                        funcao_predicao = realizar_predicao_rf_custom

                    with st.spinner(spinner_message):
                        # Chama a fun√ß√£o de predi√ß√£o selecionada
                        probs = funcao_predicao(df_bin_f, ini_ia, fim_ia)

                        if probs is not None and len(probs) == 60:
                            # 4. EXIBI√á√ÉO DE RESULTADOS (C√ìDIGO GEN√âRICO)
                            # Esta parte √© a mesma para ambos os modelos
                            df_prev = pd.DataFrame({'Dezena': range(1, 61), 'Probabilidade': probs}).sort_values(
                                'Probabilidade', ascending=False)
                            pool_ia = df_prev.head(qtd_sugerida)
                            dezenas_sugeridas = sorted(pool_ia['Dezena'].tolist())

                            st.write(f"### üéØ Pool de {qtd_sugerida} Dezenas Sugeridas pelo {modelo_escolhido}")
                            st.code(", ".join(f"{d:02d}" for d in dezenas_sugeridas), language='text')

                            # Backtesting
                            concurso_real = df_bruto[df_bruto["Concurso"] == proximo_alvo]
                            if not concurso_real.empty:
                                st.divider()
                                st.write(f"### ‚öñÔ∏è Verifica√ß√£o com o Resultado Real do Concurso {proximo_alvo}")
                                reais = [int(n) for n in concurso_real[cols_b].values[0]]
                                acertos = set(dezenas_sugeridas).intersection(set(reais))

                                c_ver1, c_ver2 = st.columns(2)
                                texto_reais = ", ".join(map(str, sorted(reais)))
                                c_ver1.markdown(f"**N√∫meros Sorteados:**\n`{texto_reais}`")
                                c_ver1.metric(f"Acertos do {modelo_escolhido} no Pool", len(acertos))

                                if len(acertos) >= 4:
                                    st.balloons()
                                    c_ver2.success(f"üî• Excelente! O pool capturou {len(acertos)} acertos.")
                                else:
                                    c_ver2.warning(f"O pool capturou {len(acertos)} acertos.")

                            # Gr√°fico
                            fig_ia = px.bar(pool_ia, x='Dezena', y='Probabilidade',
                                            title=f"For√ßa Estat√≠stica das Top {qtd_sugerida} Dezenas ({modelo_escolhido})",
                                            labels={'Dezena': 'N√∫mero da Bola', 'Probabilidade': 'Peso do Modelo'})
                            fig_ia.update_xaxes(type='category')
                            st.plotly_chart(fig_ia, width="stretch") # use_container_width=True trocado por po width=Stretch
                        else:
                            st.error("Dados insuficientes para este intervalo de treino. Tente um intervalo maior.")
        except Exception as e:
            st.error(f"Erro em Gerador, Analisador e Predi√ß√£o.  \n{e}")

        # Dados Brutos, Binarios, Governan√ßa, Metodologias
        try:
            st.divider()
            tabelaBasica = st.tabs(["üìä Dados Brutos", "üî¢ Dados Bin√°rio", "üõ°Ô∏è Governan√ßa", "üìñ Metodologias"])
            with tabelaBasica[0]:
                # 1. Primeiro, criamos uma c√≥pia da sele√ß√£o para evitar o aviso de 'SettingWithCopyWarning'
                # e j√° invertemos a ordem com o .iloc[::-1]
                df_view = df_bruto_f[['Bola1', 'Bola2', 'Bola3', 'Bola4', 'Bola5', 'Bola6', 'Concurso', 'Data do Sorteio']].iloc[::-1].copy()

                # 2. Convertemos todos os nomes de colunas para string (resolve o UserWarning de mixed type)
                df_view.columns = df_view.columns.astype(str)

                # 3. Exibimos no Streamlit com a sintaxe de 2026
                st.dataframe(
                    df_view,
                    width="stretch",
                    hide_index=True
                )
            with tabelaBasica[1]:
                st.dataframe(df_bin_f.iloc[::-1], width="stretch", hide_index=True)
            with tabelaBasica[2]:  # Governan√ßa
                st.subheader("üõ°Ô∏è Governan√ßa, √âtica e Transpar√™ncia")
                c1, c2 = st.columns(2)
                with c1:
                    st.write("**Integridade dos Dados**")
                    integridade = (len(df_bruto_f) / (c_fim - c_ini + 1)) * 100 if (c_fim - c_ini) > 0 else 100
                    st.success(f"N√≠vel de Integridade: {integridade:.2f}%")
                    st.info(f"Amostra analisadas: {len(df_bruto_f)}")
                with c2:
                    st.write("**Fonte e √âtica**")
                    st.write("- **Fonte:** Loterias Caixa (Dados Oficiais)")
                    st.write("- **Uso √âtico:** Estudo estat√≠stico. N√£o garante ganhos.")
                    st.write("- **Transpar√™ncia:** Algoritmos: SIPP, Apriori, FP-Growth, Random Forest, KMeans.")
            with tabelaBasica[3]:
                st.subheader("üìñ Metodologia SIPP e CRISP-DM na Minera√ß√£o")
                st.markdown("""
                <div class='crisp-box'>
                <b>1. Business Understanding (Entendimento do Neg√≥cio):</b> 
                <p>O objetivo deste projeto √© identificar padr√µes estat√≠sticos e de associa√ß√£o nos sorteios da Mega Sena, este 
                trabalho n√£o t√™m preten√ß√£o de realizar previs√µes de jogos ou auxiliar na tomada de decis√£o.</p>
        
                <p>Objetivo principal e baseado na analise de dadosdados, e estudos probabilisticos, para tal foi usado uma mescla
                 das metodologias SIPP e CRISP-DM</p>
        
                <p>A metodologia SIPP(acr√¥nimo para Sele√ß√£o, Integra√ß√£o, Processamento e Predi√ß√£o) √© um framework estruturado
                utilizado na minera√ß√£o de dados(Data Mining) para transformar dados brutos em conhecimento √∫til. Embora o modelo 
                CRISP - DM seja o padr√£o mais conhecido da ind√∫stria, o SIPP √© frequentemente aplicado em contextos acad√™micos e 
                espec√≠ficos de an√°lise t√©cnica por ser o mais direto nas etapas operacionais de manipula√ß√£o de dados</p></div>
        
                <div class='crisp-box'>
                <b>2. Data Understanding (Entendimento dos Dados):</b> 
                O sistema faz a coleta autom√°tica de dados direto da Caixa Economica Federal, realiza an√°lise de integridade e 
                faz a explora√ß√£o visual, apresentando tend√™ncias (paridade, somas).</div>
        
                <div class='crisp-box'>
                <b>3. Data Preparation (Prepara√ß√£o dos Dados):</b> 
                √â realizada uma transforma√ß√£o dos dados dos sorteios em uma matriz bin√°ria (One-Hot Encoding) e aplica√ß√£o de 
                pesos temporais (Linear/Exponencial), grande parte dos processos e algoritimos s√£o aplicados na base de dados binaria.</div>
        
                <div class='crisp-box'>
                <b>4. Modeling (Modelagem):</b> 
                E realizado uma aplica√ß√£o de algoritmos de Associa√ß√£o (Apriori/FP-Growth), Agrupamento (K-Means) e Predi√ß√£o (Random Forest).</div>
        
                <div class='crisp-box'>
                <b>5. Evaluation (Avalia√ß√£o):</b> 
                √â realizado uso de m√©tricas como Suporte, Confian√ßa, Lift e Probabilidades para Predi√ß√£o afim de validar os padr√µes encontrados.</div>
        
                <div class='crisp-box'>
                <b>6. Deployment (Implanta√ß√£o):</b> Disponibiliza√ß√£o do conhecimento atrav√©s de uma interface interativa utilizando o em Streamlit e Python.</div>
                """, unsafe_allow_html=True)
            st.divider()
        except Exception as e:
            st.error(f"Erro em Dados brutos, Binarios, Governan√ßa e Metodologia.  \n{e}")

elif st.session_state["authentication_status"] is False:
    st.error('Usu√°rio ou senha incorretos')
elif st.session_state["authentication_status"] is None:
    st.warning('Por favor, insira seu usu√°rio e senha.')

st.markdown(f'<div class="footer-text notranslate">¬© {NOME_SISTEMA} {VERSAO} | 2026 | By: {PROGRAMADOR}</div>', unsafe_allow_html=True)
